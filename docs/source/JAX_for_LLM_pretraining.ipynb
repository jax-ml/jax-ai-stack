{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "NIOXoY1xgiww"
   },
   "source": [
    "# Pre-training an LLM (miniGPT)\n",
    "\n",
    "[![Open in Colab](https://colab.research.google.com/assets/colab-badge.svg)](https://colab.research.google.com/github/jax-ml/jax-ai-stack/blob/main/docs/source/JAX_for_LLM_pretraining.ipynb)\n",
    "\n",
    "This tutorial demonstrates how to use JAX/Flax for LLM pretraining via data and tensor parallelism. It is originally inspired by this [Keras miniGPT tutorial](https://keras.io/examples/generative/text_generation_with_miniature_gpt/).\n",
    "\n",
    "We will use Google TPUs and [SPMD](https://en.wikipedia.org/wiki/Single_program,_multiple_data) to train a language model `miniGPT`. Instead of using a GPU, you should use the free TPU on Colab or Kaggle for this tutorial."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "hTmz5Cbco7n_"
   },
   "source": [
    "## Setup\n",
    "\n",
    "Install JAX and Flax first. We will install Tiktoken for tokenization and Grain for data loading as well."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "6zMsOIc7ouCO",
    "outputId": "037d56a9-b18f-4504-f80a-3a4fa2945068"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m780.7/780.7 kB\u001b[0m \u001b[31m6.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m2.2/2.2 MB\u001b[0m \u001b[31m54.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m289.6/289.6 kB\u001b[0m \u001b[31m8.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m270.5/270.5 kB\u001b[0m \u001b[31m13.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m62.5/62.5 kB\u001b[0m \u001b[31m2.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m15.3/15.3 MB\u001b[0m \u001b[31m61.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m128.1/128.1 kB\u001b[0m \u001b[31m6.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m42.4/42.4 kB\u001b[0m \u001b[31m1.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m49.5/49.5 kB\u001b[0m \u001b[31m1.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25h\u001b[31mERROR: pip's dependency resolver does not currently take into account all the packages that are installed. This behaviour is the source of the following dependency conflicts.\n",
      "tensorflow 2.15.0 requires ml-dtypes~=0.2.0, but you have ml-dtypes 0.4.0 which is incompatible.\u001b[0m\u001b[31m\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m1.2/1.2 MB\u001b[0m \u001b[31m15.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m419.0/419.0 kB\u001b[0m \u001b[31m20.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m8.3/8.3 MB\u001b[0m \u001b[31m99.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m61.0/61.0 kB\u001b[0m \u001b[31m3.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25h"
     ]
    }
   ],
   "source": [
    "!pip install -q jax-ai-stack\n",
    "!pip install -Uq tiktoken grain matplotlib"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "Rcji_799n4eA"
   },
   "source": [
    "Confirm we have TPUs set up."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "LS9sQEY3n0mB",
    "outputId": "9ffcf3a6-20ef-4f80-b006-f5d3c5644a15"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[TpuDevice(id=0, process_index=0, coords=(0,0,0), core_on_chip=0),\n",
       " TpuDevice(id=1, process_index=0, coords=(0,0,0), core_on_chip=1),\n",
       " TpuDevice(id=2, process_index=0, coords=(1,0,0), core_on_chip=0),\n",
       " TpuDevice(id=3, process_index=0, coords=(1,0,0), core_on_chip=1),\n",
       " TpuDevice(id=4, process_index=0, coords=(0,1,0), core_on_chip=0),\n",
       " TpuDevice(id=5, process_index=0, coords=(0,1,0), core_on_chip=1),\n",
       " TpuDevice(id=6, process_index=0, coords=(1,1,0), core_on_chip=0),\n",
       " TpuDevice(id=7, process_index=0, coords=(1,1,0), core_on_chip=1)]"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import jax\n",
    "jax.devices()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "OHzJ_bokoovZ"
   },
   "source": [
    "Get the [TinyStories dataset from Hugging Face](https://huggingface.co/datasets/roneneldan/TinyStories). We only use the training split."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "wUjQsgQEmI1N",
    "outputId": "e6eff24e-5578-4277-a0f9-24e27bd91ee0"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--2024-11-01 02:50:38--  https://huggingface.co/datasets/roneneldan/TinyStories/resolve/main/TinyStories-train.txt?download=true\n",
      "Resolving huggingface.co (huggingface.co)... 65.8.243.46, 65.8.243.92, 65.8.243.90, ...\n",
      "Connecting to huggingface.co (huggingface.co)|65.8.243.46|:443... connected.\n",
      "HTTP request sent, awaiting response... 302 Found\n",
      "Location: https://cdn-lfs.hf.co/repos/42/7f/427f7497b6c6596c18b46d5a72e61364fcad12aa433c60a0dbd4d344477b9d81/c5cf5e22ff13614e830afbe61a99fbcbe8bcb7dd72252b989fa1117a368d401f?response-content-disposition=attachment%3B+filename*%3DUTF-8%27%27TinyStories-train.txt%3B+filename%3D%22TinyStories-train.txt%22%3B&response-content-type=text%2Fplain&Expires=1730688639&Policy=eyJTdGF0ZW1lbnQiOlt7IkNvbmRpdGlvbiI6eyJEYXRlTGVzc1RoYW4iOnsiQVdTOkVwb2NoVGltZSI6MTczMDY4ODYzOX19LCJSZXNvdXJjZSI6Imh0dHBzOi8vY2RuLWxmcy5oZi5jby9yZXBvcy80Mi83Zi80MjdmNzQ5N2I2YzY1OTZjMThiNDZkNWE3MmU2MTM2NGZjYWQxMmFhNDMzYzYwYTBkYmQ0ZDM0NDQ3N2I5ZDgxL2M1Y2Y1ZTIyZmYxMzYxNGU4MzBhZmJlNjFhOTlmYmNiZThiY2I3ZGQ3MjI1MmI5ODlmYTExMTdhMzY4ZDQwMWY%7EcmVzcG9uc2UtY29udGVudC1kaXNwb3NpdGlvbj0qJnJlc3BvbnNlLWNvbnRlbnQtdHlwZT0qIn1dfQ__&Signature=oQHJBcHVix9N1HnNsJSj7KK-BoqdXdl6NRh%7E1ilGx-ROnLrZxKINfonOtva5e5Xf9KQVNl6QQkx5gNw4iMTmS6JRFB%7EcXdTcFjrHSnBxwLRZkMCBKAv3oHhRnJ6I2rV8iBAZTq%7E-caDCLFvBrgT9pcEFakh3-5mSp%7ER7hnNqE5lcE5n7tzXS0l-8tOShDmR5aUCFPStZHfPbyS3MwCAdc2KoqXdqzRf9M4WvXWB78El7WGxse0DrTQFbGGW1kjpvBOqzljH0Qn6WqsiBockhHDbwE1nQmGfxKrbreXenAKdOsUTN9fuRKl-6srhI2xGKFpfu3IGDEN%7Ebmwg8CnwAfQ__&Key-Pair-Id=K3RPWS32NSSJCE [following]\n",
      "--2024-11-01 02:50:39--  https://cdn-lfs.hf.co/repos/42/7f/427f7497b6c6596c18b46d5a72e61364fcad12aa433c60a0dbd4d344477b9d81/c5cf5e22ff13614e830afbe61a99fbcbe8bcb7dd72252b989fa1117a368d401f?response-content-disposition=attachment%3B+filename*%3DUTF-8%27%27TinyStories-train.txt%3B+filename%3D%22TinyStories-train.txt%22%3B&response-content-type=text%2Fplain&Expires=1730688639&Policy=eyJTdGF0ZW1lbnQiOlt7IkNvbmRpdGlvbiI6eyJEYXRlTGVzc1RoYW4iOnsiQVdTOkVwb2NoVGltZSI6MTczMDY4ODYzOX19LCJSZXNvdXJjZSI6Imh0dHBzOi8vY2RuLWxmcy5oZi5jby9yZXBvcy80Mi83Zi80MjdmNzQ5N2I2YzY1OTZjMThiNDZkNWE3MmU2MTM2NGZjYWQxMmFhNDMzYzYwYTBkYmQ0ZDM0NDQ3N2I5ZDgxL2M1Y2Y1ZTIyZmYxMzYxNGU4MzBhZmJlNjFhOTlmYmNiZThiY2I3ZGQ3MjI1MmI5ODlmYTExMTdhMzY4ZDQwMWY%7EcmVzcG9uc2UtY29udGVudC1kaXNwb3NpdGlvbj0qJnJlc3BvbnNlLWNvbnRlbnQtdHlwZT0qIn1dfQ__&Signature=oQHJBcHVix9N1HnNsJSj7KK-BoqdXdl6NRh%7E1ilGx-ROnLrZxKINfonOtva5e5Xf9KQVNl6QQkx5gNw4iMTmS6JRFB%7EcXdTcFjrHSnBxwLRZkMCBKAv3oHhRnJ6I2rV8iBAZTq%7E-caDCLFvBrgT9pcEFakh3-5mSp%7ER7hnNqE5lcE5n7tzXS0l-8tOShDmR5aUCFPStZHfPbyS3MwCAdc2KoqXdqzRf9M4WvXWB78El7WGxse0DrTQFbGGW1kjpvBOqzljH0Qn6WqsiBockhHDbwE1nQmGfxKrbreXenAKdOsUTN9fuRKl-6srhI2xGKFpfu3IGDEN%7Ebmwg8CnwAfQ__&Key-Pair-Id=K3RPWS32NSSJCE\n",
      "Resolving cdn-lfs.hf.co (cdn-lfs.hf.co)... 3.167.152.12, 3.167.152.119, 3.167.152.37, ...\n",
      "Connecting to cdn-lfs.hf.co (cdn-lfs.hf.co)|3.167.152.12|:443... connected.\n",
      "HTTP request sent, awaiting response... 200 OK\n",
      "Length: 1924281556 (1.8G) [text/plain]\n",
      "Saving to: ‘TinyStories-train.txt’\n",
      "\n",
      "TinyStories-train.t 100%[===================>]   1.79G  38.1MB/s    in 45s     \n",
      "\n",
      "2024-11-01 02:51:24 (40.7 MB/s) - ‘TinyStories-train.txt’ saved [1924281556/1924281556]\n",
      "\n"
     ]
    }
   ],
   "source": [
    "!wget https://huggingface.co/datasets/roneneldan/TinyStories/resolve/main/TinyStories-train.txt?download=true -O TinyStories-train.txt"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "sKE2uUafLobI"
   },
   "source": [
    "Take care of the imports."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "id": "MKYFNOhdLq98"
   },
   "outputs": [],
   "source": [
    "import jax\n",
    "import jax.numpy as jnp\n",
    "import flax.nnx as nnx\n",
    "import optax\n",
    "from dataclasses import dataclass\n",
    "import grain.python as pygrain\n",
    "from jax.experimental import mesh_utils\n",
    "from jax.sharding import Mesh, PartitionSpec as P, NamedSharding\n",
    "import pandas as pd\n",
    "import tiktoken\n",
    "import time"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "rPyt7MV6prz1"
   },
   "source": [
    "## Build the model\n",
    "\n",
    "One of the biggest advantages of JAX is how easy it is to enable parallelism. To demonstrate this, we are going to use 4-way data parallel and 2-way tensor parallel. Tensor parallelism is one kind of model parallelism, which shards model tensors; there are other kinds of model parallelism, which we won't cover in this tutorial.\n",
    "\n",
    "As a background, data parallel means splitting a batch of training data into multiple parts (this is called sharding); this way you can use bigger batch sizes to accelerate training, if you have multiple devices that can run in parallel. On the other hand, you can shard not just the training data. Sometimes your model is so big that the model parameters don't fit on a single accelerator. In this case, tensor parallel helps splitting the parameter tensors within a model onto multiple accelerators so that the model can actually run. Both approaches can take advantage of modern accelerators. For example, TPU v2 on the free Colab tier offers 4 chips, each of which has 2 TPU cores. So this architeture works well with 4-way data parallel and 2-way tensor parallel.\n",
    "\n",
    "To get a detailed understanding of how JAX automatic parallelism works, please refer to this [JAX tutorial](https://jax.readthedocs.io/en/latest/notebooks/Distributed_arrays_and_automatic_parallelization.html#way-batch-data-parallelism-and-2-way-model-tensor-parallelism). In our case to leverage parallelism, we first need to define a `Mesh`, which declares the TPU resources with 2 axes: `batch` axis as 4 and `model` axis as 2, which maps to the TPU v2 cores. Here, the `model` axis enables the tensor parallel for us."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "id": "xuMlCK3Q8WJD"
   },
   "outputs": [],
   "source": [
    "mesh = Mesh(mesh_utils.create_device_mesh((4, 2)), ('batch', 'model'))\n",
    "\n",
    "### Alternative 8-way data parallel with only one line of code change.\n",
    "### JAX enables quick experimentation with different partitioning strategies\n",
    "### like this. We will come back to this point at the end of this tutorial.\n",
    "# mesh = Mesh(mesh_utils.create_device_mesh((8, 1)), ('batch', 'model'))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "_ZKdhNo98NgG"
   },
   "source": [
    "We are going to use the GPT-2 tokenizer via [Tiktoken](https://github.com/openai/tiktoken)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "id": "iWbkk1V7-Isg"
   },
   "outputs": [],
   "source": [
    "tokenizer = tiktoken.get_encoding(\"gpt2\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "0XHQ0BQ9-KIj"
   },
   "source": [
    "To use model parallel, we need to tell JAX compiler how to shard the model tensors. We first use `PartitionSpec` (shorted to `P` in the code) to describe how to shard a tensor: in our case a tensor could be either sharded along the `model` axis or be replicated on other dimensions (which is denoted by `None`). [`NamedSharding`](https://jax.readthedocs.io/en/latest/jax.sharding.html#jax.sharding.NamedSharding) can then specify how a model tensor is sharded across the devices mesh using a pair of `Mesh` and `PartitionSpec`.\n",
    "\n",
    "Finally, we use `nnx.with_partitioning` to let the layers know that their tensors need to be shared/replicated according to our spec. You need to do this for every tensor/layer in your model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "id": "z0p-IHurrB9i"
   },
   "outputs": [],
   "source": [
    "def causal_attention_mask(seq_len):\n",
    "    return jnp.tril(jnp.ones((seq_len, seq_len)))\n",
    "\n",
    "class TransformerBlock(nnx.Module):\n",
    "    def __init__(self, embed_dim: int, num_heads: int, ff_dim: int, *, rngs: nnx.Rngs, rate: float = 0.1):\n",
    "        self.mha = nnx.MultiHeadAttention(num_heads=num_heads,\n",
    "                                          in_features=embed_dim,\n",
    "                                          kernel_init=nnx.with_partitioning(nnx.initializers.xavier_uniform(), NamedSharding(mesh, P(None, 'model'))),\n",
    "                                          bias_init=nnx.with_partitioning(nnx.initializers.zeros_init(), NamedSharding(mesh, P('model'))),\n",
    "                                          rngs=rngs)\n",
    "        self.dropout1 = nnx.Dropout(rate=rate)\n",
    "        self.layer_norm1 = nnx.LayerNorm(epsilon=1e-6,\n",
    "                                         num_features=embed_dim,\n",
    "                                         scale_init=nnx.with_partitioning(nnx.initializers.ones_init(), NamedSharding(mesh, P('model'))),\n",
    "                                         bias_init=nnx.with_partitioning(nnx.initializers.zeros_init(), NamedSharding(mesh, P('model'))),\n",
    "                                         rngs=rngs)\n",
    "        self.linear1 = nnx.Linear(in_features=embed_dim,\n",
    "                                  out_features=ff_dim,\n",
    "                                  kernel_init=nnx.with_partitioning(nnx.initializers.xavier_uniform(), NamedSharding(mesh, P(None, 'model'))),\n",
    "                                  bias_init=nnx.with_partitioning(nnx.initializers.zeros_init(), NamedSharding(mesh, P('model'))),\n",
    "                                  rngs=rngs)\n",
    "        self.linear2 = nnx.Linear(in_features=ff_dim,\n",
    "                                  out_features=embed_dim,\n",
    "                                  kernel_init=nnx.with_partitioning(nnx.initializers.xavier_uniform(), NamedSharding(mesh, P(None, 'model'))),\n",
    "                                  bias_init=nnx.with_partitioning(nnx.initializers.zeros_init(), NamedSharding(mesh, P('model'))),\n",
    "                                  rngs=rngs)\n",
    "        self.dropout2 = nnx.Dropout(rate=rate)\n",
    "        self.layer_norm2 = nnx.LayerNorm(epsilon=1e-6,\n",
    "                                         num_features=embed_dim,\n",
    "                                         scale_init=nnx.with_partitioning(nnx.initializers.ones_init(), NamedSharding(mesh, P(None, 'model'))),\n",
    "                                         bias_init=nnx.with_partitioning(nnx.initializers.zeros_init(), NamedSharding(mesh, P(None, 'model'))),\n",
    "                                         rngs=rngs)\n",
    "\n",
    "\n",
    "    def __call__(self, inputs, training: bool = False):\n",
    "        input_shape = inputs.shape\n",
    "        _, seq_len, _ = input_shape\n",
    "\n",
    "        # Create causal mask\n",
    "        mask = causal_attention_mask(seq_len)\n",
    "\n",
    "        # Apply MultiHeadAttention with causal mask\n",
    "        attention_output = self.mha(\n",
    "            inputs_q=inputs,\n",
    "            mask=mask,\n",
    "            decode=False\n",
    "        )\n",
    "        attention_output = self.dropout1(attention_output, deterministic=not training)\n",
    "        out1 = self.layer_norm1(inputs + attention_output)\n",
    "\n",
    "        # Feed-forward network\n",
    "        ffn_output = self.linear1(out1)\n",
    "        ffn_output = nnx.relu(ffn_output)\n",
    "        ffn_output = self.linear2(ffn_output)\n",
    "        ffn_output = self.dropout2(ffn_output, deterministic=not training)\n",
    "\n",
    "        return self.layer_norm2(out1 + ffn_output)\n",
    "\n",
    "\n",
    "class TokenAndPositionEmbedding(nnx.Module):\n",
    "\n",
    "    def __init__(self, maxlen: int, vocab_size: int, embed_dim: int, *, rngs: nnx.Rngs):\n",
    "        self.token_emb = nnx.Embed(num_embeddings=vocab_size, features=embed_dim, rngs=rngs)\n",
    "        self.pos_emb = nnx.Embed(num_embeddings=maxlen, features=embed_dim, rngs=rngs)\n",
    "\n",
    "    def __call__(self, x):\n",
    "        positions = jnp.arange(0, x.shape[1])[None, :]\n",
    "        position_embedding = self.pos_emb(positions)\n",
    "        token_embedding = self.token_emb(x)\n",
    "        return token_embedding + position_embedding\n",
    "\n",
    "\n",
    "class MiniGPT(nnx.Module):\n",
    "    def __init__(self, maxlen: int, vocab_size: int, embed_dim: int, num_heads: int, feed_forward_dim: int, num_transformer_blocks: int, rngs: nnx.Rngs):\n",
    "        self.embedding_layer = TokenAndPositionEmbedding(\n",
    "                    maxlen, vocab_size, embed_dim, rngs=rngs\n",
    "                )\n",
    "        self.transformer_blocks = [TransformerBlock(\n",
    "            embed_dim, num_heads, feed_forward_dim, rngs=rngs\n",
    "        ) for _ in range(num_transformer_blocks)]\n",
    "\n",
    "        self.output_layer = nnx.Linear(in_features=embed_dim,\n",
    "                                       out_features=vocab_size,\n",
    "                                       kernel_init=nnx.with_partitioning(nnx.initializers.xavier_uniform(), NamedSharding(mesh, P(None, 'model'))),\n",
    "                                       bias_init=nnx.with_partitioning(nnx.initializers.zeros_init(), NamedSharding(mesh, P(None, 'model'))),\n",
    "                                       rngs=rngs)\n",
    "\n",
    "    def __call__(self, inputs, training: bool = False):\n",
    "        x = self.embedding_layer(inputs)\n",
    "        for transformer_block in self.transformer_blocks:\n",
    "            x = transformer_block(x, training=training)\n",
    "        outputs = self.output_layer(x)\n",
    "        return outputs\n",
    "\n",
    "    def generate_text(self, max_tokens: int, start_tokens: [int], top_k=10):\n",
    "        def sample_from(logits):\n",
    "            logits, indices = jax.lax.top_k(logits, k=top_k)\n",
    "            logits = nnx.softmax(logits)\n",
    "            return jax.random.choice(jax.random.PRNGKey(0), indices, p=logits)\n",
    "\n",
    "        def generate_step(start_tokens):\n",
    "            pad_len = maxlen - len(start_tokens)\n",
    "            sample_index = len(start_tokens) - 1\n",
    "            if pad_len < 0:\n",
    "                x = jnp.array(start_tokens[:maxlen])\n",
    "                sample_index = maxlen - 1\n",
    "            elif pad_len > 0:\n",
    "                x = jnp.array(start_tokens + [0] * pad_len)\n",
    "            else:\n",
    "                x = jnp.array(start_tokens)\n",
    "\n",
    "            x = x[None, :]\n",
    "            logits = self(x)\n",
    "            next_token = sample_from(logits[0][sample_index])\n",
    "            return next_token\n",
    "\n",
    "        generated = []\n",
    "        for _ in range(max_tokens):\n",
    "            next_token = generate_step(start_tokens + generated)\n",
    "            # Truncate whatever is after '<|endoftext|>' (stop word)\n",
    "            if next_token == tokenizer.encode('<|endoftext|>', allowed_special={'<|endoftext|>'})[0]:\n",
    "              break\n",
    "            generated.append(int(next_token))\n",
    "        return tokenizer.decode(start_tokens + generated)\n",
    "\n",
    "def create_model(rngs):\n",
    "    return MiniGPT(maxlen, vocab_size, embed_dim, num_heads, feed_forward_dim, num_transformer_blocks=4, rngs=rngs)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "igX_eoGNMTGR"
   },
   "source": [
    "Set some hyperparameters."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "id": "GRhiDsCrMZRp"
   },
   "outputs": [],
   "source": [
    "vocab_size = tokenizer.n_vocab\n",
    "num_transformer_blocks = 8\n",
    "maxlen = 256\n",
    "embed_dim = 256\n",
    "num_heads = 8\n",
    "feed_forward_dim = 256\n",
    "batch_size = 256 # You can set a bigger batch size if using Kaggle TPU\n",
    "num_epochs = 1"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "mI1ci-HyMspJ"
   },
   "source": [
    "## Prepare data\n",
    "\n",
    "Data loading and preprocessing with [Grain](https://github.com/google/grain)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "id": "rGUFsn1GMuzh"
   },
   "outputs": [],
   "source": [
    "@dataclass\n",
    "class TextDataset:\n",
    "    data: list\n",
    "    maxlen: int\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.data)\n",
    "\n",
    "    def __getitem__(self, idx: int):\n",
    "        # Use Tiktoken for tokenization\n",
    "        encoding = tokenizer.encode(self.data[idx], allowed_special={'<|endoftext|>'})[:self.maxlen]  # Tokenize and truncate\n",
    "        return encoding + [0] * (self.maxlen - len(encoding))  # Pad to maxlen\n",
    "\n",
    "def load_and_preprocess_data(file_path, batch_size, maxlen):\n",
    "\n",
    "    with open(file_path, 'r') as f:\n",
    "      text = f.read()\n",
    "\n",
    "    stories = text.split('<|endoftext|>')\n",
    "    stories = [story+'<|endoftext|>' for story in stories if story.strip()]\n",
    "    df = pd.DataFrame({'text': stories})\n",
    "    data = df['text'].dropna().tolist()\n",
    "    dataset = TextDataset(data, maxlen)\n",
    "\n",
    "    sampler = pygrain.IndexSampler(\n",
    "        len(dataset),\n",
    "        shuffle=False,\n",
    "        seed=42,\n",
    "        shard_options=pygrain.NoSharding(),\n",
    "        num_epochs=num_epochs,\n",
    "    )\n",
    "\n",
    "    dl = pygrain.DataLoader(\n",
    "        data_source=dataset,\n",
    "        sampler=sampler,\n",
    "        operations=[pygrain.Batch(batch_size=batch_size, drop_remainder=True)],\n",
    "    )\n",
    "\n",
    "    return dl\n",
    "\n",
    "text_dl = load_and_preprocess_data('TinyStories-train.txt', batch_size, maxlen)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "BKVSD8KSM1um"
   },
   "source": [
    "## Train the model\n",
    "\n",
    "Define loss function and training step function."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "id": "8rRuTmABNV4b"
   },
   "outputs": [],
   "source": [
    "def loss_fn(model, batch):\n",
    "    logits = model(batch[0])\n",
    "    loss = optax.softmax_cross_entropy_with_integer_labels(logits=logits, labels=batch[1]).mean()\n",
    "    return loss, logits\n",
    "\n",
    "@nnx.jit\n",
    "def train_step(model: MiniGPT, optimizer: nnx.Optimizer, metrics: nnx.MultiMetric, batch):\n",
    "    grad_fn = nnx.value_and_grad(loss_fn, has_aux=True)\n",
    "    (loss, logits), grads = grad_fn(model, batch)\n",
    "    metrics.update(loss=loss, logits=logits, lables=batch[1])\n",
    "    optimizer.update(grads)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "5um2vkeUNckm"
   },
   "source": [
    "Start training. It takes ~50 minutes on Colab.\n",
    "\n",
    "Note that for data parallel, we are sharding the training data along the `batch` axis using `jax.device_put` with `NamedeSharding`.\n",
    "\n",
    "We are also using the `jax.vmap` transformation to produce the target sequences faster."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "Ysl6CsfENeJN",
    "outputId": "5dd06dca-f030-4927-a9b6-35d412da535c"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Initial generated text:\n",
      "Once upon a time Christina Raven Liqu Everyday seaw Spl digit mini Hungarian wasteful USC recurrent brawl towers summAvailability manualsidsAvailability Jord staleEarlier 303 Latter soakinginated pierced acquaint propaganda differentlyBesides Splambling Significant processing locals FoundingFlickrverbalSquaresth pixels CON repetitivebass%; dartsKN ushered sim wasteful Qi510 174 (_ Hillaryall hopeddalePref recurrentbassoves AOL ushered Hunt manuals NietzscheidsBY Equ souls correctedresaKN ghamblinguador contest cornerback bannedKN realizedSix summlargest gh fastest req influences cursingosureelse delighted wrecked donors codsedentiallyindaletteogenicAI summ wasteful USCesm shaped Garrett resistance grandchildren souls babyStatementambling fastestirin AWSiden groundedKen%; aboarddogs seaw Sultan Sachs Sonic ArchivesINE darts belts asylumei simette expands targetintergroupon Graveyard Graveyard398Jordan 66 medication Leadership 174?: seaw manuals summ asylumrw slice manualsiries Prometheus� Seat correctedINE denomination summ vastlyKNKN belts?: contest PamelaidiumKN themHI seawKN minions summ squadKN Joker sacredamblingKNuckyKNette 69 Xan 69ourse notificationuku Sitting cosmeticakesGro McAuliffeilles Graveyard differe <-Jordan Archives 180 Puppet cabinetodcast spir305 bannedambling 66 medicationbass victory relatingakespe Rover GarrettPrefppo sim recurrent manualsidsrg eveningsossus asylum Puppet hydra SultanProxy 66 chew Jokeranswer%;Loc Australian awaidiumdale landed Luahangはambling SuddenlyKN victory victory victory victory\n",
      "\n",
      "Step 200, Loss: 4.541538715362549, Elapsed Time: 119.14 seconds\n",
      "Generated text:\n",
      "Once upon a time was a time was was was was very little girl, day was so happy, her little girl, her little little little little little little little little little little little little little little little little little little little little little little little little little little little little little little little little little little little little little little little little little little little little little little little little little little little little little little little little little little little little little little little little little little little little little little little little little little little little little little little little little little little little little little little little little little little little little little little little little little little little little little little little little little little little little little little little little little little little little little little little little little little little little little little little little little little little little little little little little little little little little little little little little little little little little little little little little little little little little little little little little little little little little little little little little little little little little little little little little little little little little little little little little little little little little little little little little little little little little little little little little little little little little little little little little little little little little little little little little little little little little little little little little little little little little little little!!!!\n",
      "\n",
      "Step 400, Loss: 2.8348119258880615, Elapsed Time: 103.58 seconds\n",
      "Generated text:\n",
      "Once upon a time there was a small cat named Jack. Tim was a little girl who lived in the world and wanted to explore the forest. The dog, he had a new toy car and his mommy and daddy. He wanted to be so much. He went to help the ball. He said to be careful to go and said, \"What's wrong!\"\n",
      "After they found the other kids said, Timmy was so excited and he could see his friend. Timmy said, \"Let's play in the other animals, but I want to help.\"\n",
      "Timmy smiled and they played with a while. Timmy said, \"It's not listen to play. \"Thank you. \"You are happy.\"\n",
      "\n",
      "\n",
      "Step 600, Loss: 2.3290421962738037, Elapsed Time: 69.78 seconds\n",
      "Generated text:\n",
      "Once upon a time, there was a little girl named Lily. She was very curious and loved to play outside in the garden. One day, she was playing with her toys and saw a big box with a shiny red ball. The ball was shiny and wanted to climb it, but she didn't want to be too far. \n",
      "\"Hi, I can't get my toy!\" said, but Lily said, \"No, you are not yours.\" \n",
      "Lily's mom smiled and said, \"You can help me go to me!\"\n",
      "\"I want to get some candy and it,\" she said. \"That's a big dog.\"\n",
      "The cat said, \"No, we need to go home. I'm going to find some.\" \n",
      "Her mom said, \"Okay, you will get to play with me.\"\n",
      "Lily smiled and said, \"I want to get my favorite toy first!\" \n",
      "Her mom said, \"Okay, but they don't know. They both thought it is so much fun to go on their mom and have fun. They played together, but they did not wait to be friends and they had fun together. \n",
      "\n",
      "\n",
      "Step 800, Loss: 2.049470901489258, Elapsed Time: 84.69 seconds\n",
      "Generated text:\n",
      "Once upon a time, there was a little girl named Lucy was playing in the garden. She loved to run and play outside and she had lots of fun. She would always look at all day and her friends in the garden.\n",
      "One day, she was playing outside when she heard a strange noise coming from a loud noise. It was coming from a dark and it started to shake. It was a big dog, so scared.\n",
      "Her mom came into the room and said, \"That's not safe!\"\n",
      "The dog smiled and said, \"Don't worry, I will find my friend.\" Lucy and the dog started to walk in the grass, but soon she heard the sound coming from the garden, and she heard a noise. The dog ran back inside, but the door opened and saw that the shadow had a hole in a hole. Lucy and the dog became friends, and they played together all the things and they never found a beautiful spot to get home.\n",
      "\n",
      "\n",
      "Step 1000, Loss: 1.8924535512924194, Elapsed Time: 76.64 seconds\n",
      "Generated text:\n",
      "Once upon a time, there was a girl named Amy. Amy loved to go outside and play with her friends. One day, Amy saw a big tree and asked her friends, \"Can I have some best friends?\" The tree was so big that it made a special tree to get in the tree. \n",
      "Amy went to the tree and asked, \"Can I go on my tree?\" The tree replied, \"Sure, let's play together!\" \n",
      "So, Amy and the tree were very excited. Amy started to play, but it was too heavy for the tree. She started to climb and forth, but it was so far away. Amy's mom saw how fast it was. She asked, \"Why do you think this, but I want to get to be my friend?\" Amy said, \"No, it's too late, so we can't play together!\" Amy's friend started to fight and said, \"I'll be friends. Let's play together!\" Amy and Amy laughed, and laughed together, and they became best friends and they had a fun day together.\n",
      "\n",
      "\n",
      "Step 1200, Loss: 1.7993096113204956, Elapsed Time: 80.74 seconds\n",
      "Generated text:\n",
      "Once upon a time, there was a little girl named Amy. She loved to go outside and play in the sunshine. One day, she went outside to play with her friends. They went on a sunny day and found a shiny ball. \n",
      "Amy wanted to see the ball and it started to fly it. But then, a little girl came to her friend. Her friend saw her and asked if she could join the bird. The bird said yes and Lily took it to her house.\n",
      "Amy was very happy and she started to sing and dance with her friend. They sang together and danced until the sun came up. They laughed and danced together, laughing and having fun. They played together all day and the day long.\n",
      "\n",
      "\n",
      "Step 1400, Loss: 1.7445931434631348, Elapsed Time: 69.74 seconds\n",
      "Generated text:\n",
      "Once upon a time, there was a girl named Sue. She was only three years old. Sue loved to explore. One day, she saw a little bird sitting on a branch. Sue was scared. She ran up to her mom and said, \"Mom, what's that noise?\" Her mom smiled and said, \"It's okay, Sue. We don't have any more fun!\"\n",
      "Sue and her mom looked around the house and found a small bird that made her feel better. It was a little bird. Sue and her mom went outside and played in the sun. They had a great time playing and laughing.\n",
      "At the end of the day, Sue said, \"Thank you, Mommy! You're welcome! You are very lucky to be a friend.\" Her mom smiled and said, \"Thank you, mommy. I love your new friend!\"\n",
      "\n",
      "\n",
      "Step 1600, Loss: 1.6877646446228027, Elapsed Time: 74.16 seconds\n",
      "Generated text:\n",
      "Once upon a time, a boy named Jack was walking down the street. He was feeling very scared. His mom told him that he had to go outside and get to play. \n",
      "One day, Jack noticed a little boy playing in the park. He wanted to play with the equipment too, but he was scared. \n",
      "Jack ran over and asked, \"Why did you get me?\" His mom said, \"I don't want to be scared. I'm sorry I can't have the equipment to take the equipment to play.\" \n",
      "Jack thought about the equipment he would make it even more fun with the equipment. So, he started to build the equipment. When he was finished, Jack felt a bit better. \n",
      "The equipment was a way to the playground, but he knew that his mom was not alone, she had to help him get better. She asked him to stay in the playground, but Jack was still happy to have the equipment to stay, but Jack couldn't.\n",
      "Jack learned that being kind was important to help and not be afraid of being ignorant and selfish. He was still happy, but he was still very selfish and always asked the equipment for help.\n",
      "\n",
      "\n",
      "Step 1800, Loss: 1.6456927061080933, Elapsed Time: 85.76 seconds\n",
      "Generated text:\n",
      "Once upon a time, there was a little girl named Mia. Mia loved to play outside in the park. One day, Mia found a shiny coin in the park. She wanted it for her birthday party, but it was too expensive. Mia thought it would not buy the coin for her birthday.\n",
      "So, Mia decided to ask her mom for the coin to buy the coin. The coin looked for a long time and said yes. Mia put the coin back in the park, but it was gone. Mia was very sad.\n",
      "So, Mia asked her mom if she could have a special day. Her mom said yes and they both went home with the coin. Mia was so happy! She said yes, but the coin was gone forever.\n",
      "\n",
      "\n",
      "Step 2000, Loss: 1.6211789846420288, Elapsed Time: 69.42 seconds\n",
      "Generated text:\n",
      "Once upon a time, there was a small boy named Tim. Tim was a small boy named Timmy. Timmy loved to play with his toy car and he loved to make noises with it.\n",
      "One day, Timmy and his toy car went to the park with his toy car. Timmy's car got stuck in the car and it crashed. Timmy's car was too fast and it hit a tree with the wheel.\n",
      "Timmy was sad because he loved his car so much. He knew he could help make his toy car better. He said, \"I will make you happy! Let's play together and make a new car.\" And Timmy and his toy car had fun together and they became good friends.\n",
      "\n",
      "\n",
      "Step 2200, Loss: 1.578463077545166, Elapsed Time: 68.18 seconds\n",
      "Generated text:\n",
      "Once upon a time, there was a little girl named Lucy. She was only three years old and loved to play with her toys. One day, she found a special treasure, a big, scary toy that was very big and she was so excited to take it home. \n",
      "But, one day, Lucy found a shiny jewel that she was very happy to find it. She opened the door and saw a beautiful necklace in the corner of the room. She wanted to see what it was like. She asked her friend, the necklace, and the necklace said, \"Can I take it home now?\" \n",
      "Lucy smiled and said, \"I can borrow it with a special diamond. It's very special because it belongs to someone else.\"\n",
      "The diamond was so happy to see Lucy and said, \"Thank you, Lucy. You are a great friend!\"\n",
      "\n",
      "\n",
      "Step 2400, Loss: 1.5326989889144897, Elapsed Time: 73.51 seconds\n",
      "Generated text:\n",
      "Once upon a time, there was a little boy named Timmy. Timmy loved to play outside in the sun. One day, Timmy saw a beautiful flower. It was so pretty!\n",
      "Timmy asked his mom, \"What is this flower?\"\n",
      "His mom replied, \"It's a flower. Do you want to play with it?\"\n",
      "Timmy nodded his head and said, \"Yes, please.\"\n",
      "Timmy was so happy and he played with the flower. They laughed and played until the sun went down.\n",
      "Suddenly, they heard a loud noise. It was a little kitten. The kitten was scared and didn't know what to do. Timmy's mom told him it was a bad ending.\n",
      "\n",
      "\n",
      "Step 2600, Loss: 1.5533288717269897, Elapsed Time: 70.30 seconds\n",
      "Generated text:\n",
      "Once upon a time, there was a little girl named Lily. She was very happy because she had a pretty blouse. One day, Lily was playing with her friend Jack came over to play. She asked, \"Can I play with you?\" \n",
      "Jack said, \"Sure, let's play with your friends!\" Lily was excited and said, \"Okay, let's play!\" They ran around the room and played with their new friends. \n",
      "As they were playing, Lily accidentally knocked over the blouse and it fell off the blouse. Jack said, \"Ouch!\" \n",
      "Lily felt embarrassed and said, \"It's okay, Lily. I'm sorry. I didn't mean to break the blouse. Let's play with it again!\" \n",
      "They both started to play and soon the blouse was over. They played together and had a lot of fun. Lily felt so happy that she didn't make her friend laugh again. She realized that sometimes things don't seem too bad and we should be different, but they still have a solution.\n",
      "\n",
      "\n",
      "Step 2800, Loss: 1.5323652029037476, Elapsed Time: 80.58 seconds\n",
      "Generated text:\n",
      "Once upon a time, there was a little boy named Tim. Tim was a good boy. He liked to play with his toys and his dog, Max. One day, Tim went to the park with his mom.\n",
      "\"Hi, Tim! I want to play with you. Do you want to play with me?\" Tim asked.\n",
      "\"Yes, Tim. Let's play together!\" his mom said.\n",
      "Tim and Max played together all day. They laughed and had lots of fun. Tim and Max were good friends.\n",
      "\"Can we play with our friends?\" Max asked.\n",
      "\"Yes, but we can play together,\" his mom said.\n",
      "Tim and Max played together. They laughed and had fun. Tim and Max were happy to play with them. They were best friends.\n",
      "\n",
      "\n",
      "Step 3000, Loss: 1.5298235416412354, Elapsed Time: 70.76 seconds\n",
      "Generated text:\n",
      "Once upon a time, there was a little girl named Lily. She was three years old and loved to explore the world around her. One day, Lily found a shiny jewel on the ground. She picked it up and looked inside the jewel. She picked it up and examined it. She showed it to her mom and they were so proud of her. \n",
      "After she was finished playing, Lily went to bed. She had so much fun that she didn't realize it was her mom had made a mistake. Her mom explained that sometimes it's important to be responsible and to listen to others. Lily was very careful and listened to her mom's advice.\n",
      "From that day on, Lily was careful and she never forgot about the jewel. She always made sure to be careful when she played. And always remember to always be careful when things happened.\n",
      "\n",
      "\n",
      "Step 3200, Loss: 1.471197485923767, Elapsed Time: 72.75 seconds\n",
      "Generated text:\n",
      "Once upon a time, there was a little boy named Tim. Tim was a curious little boy who loved to play. One day, he found a toy car in the garden. It was red and shiny. Tim was very happy and excited.\n",
      "As Tim went outside to play, he saw a little bird in the grass. The bird had a red car. Tim wanted to help the bird. He said, \"Hello, little bird. Can you help me lift my toy?\" The bird looked at Tim and said, \"Yes, please! It is so nice to be careful. You are smart and smart.\"\n",
      "Tim was very happy to help the bird. He thanked the bird and the bird flew away. Tim learned that helping others can make us feel good and smart. He learned that helping others can make us happy too.\n",
      "\n",
      "\n",
      "Step 3400, Loss: 1.5036591291427612, Elapsed Time: 71.77 seconds\n",
      "Generated text:\n",
      "Once upon a time there was a boy named Tim. He loved to go outside and play. One day, he saw a big tree with lots of branches. He wanted to climb it, but his mom said no.\n",
      "Tim tried to climb the tree, but it was too high. He was getting higher and higher until he could see what was on the top. Then he heard a loud noise coming from outside. He peeked out from the ground and saw a small bird flying above.\n",
      "Tim was so happy to be able to reach the top. He jumped and jumped up and down the tree with excitement. When he was finally caught the bird, it flew down to the tree. Tim was so proud of his success.\n",
      "He thanked the bird and continued climbing. He was very happy that he had climbed the tree, even though he couldn't get down from the tree. From then on, he made sure to stay away from the top of the tree, safe and sound.\n",
      "\n",
      "\n",
      "Step 3600, Loss: 1.4788475036621094, Elapsed Time: 76.91 seconds\n",
      "Generated text:\n",
      "Once upon a time, there was a little boy named Timmy. Timmy loved to play with his toys and watch cartoons. One day, Timmy's mommy asked him to help his mommy. Timmy was excited to help, so he got a new toy from his grandma's house. \n",
      "After a few days, Timmy's mommy gave him a special gift. Timmy was so excited to receive such a gift! It was a special gift that his grandma gave him a big hug. Timmy was so happy to have such a gift and hugged his mommy. \n",
      "After that, Timmy went to bed that night with a special gift from his grandma. He loved his present so much that he gave it a special gift to his grandma. Timmy was so happy to have a present that he had found such a beautiful gift. \n",
      "The next day, Timmy's grandma gave him a gift and gave him a gift. Timmy was so excited and couldn't wait to tell his grandma. He showed his grandma a gift for him with a present, and they all said thank you to his grandma. Timmy was so happy to receive the gift from her grandma and her gift. \n",
      "The present was that Timmy had!!!!\n",
      "\n",
      "Step 3800, Loss: 1.4588173627853394, Elapsed Time: 88.57 seconds\n",
      "Generated text:\n",
      "Once upon a time, there was a little boy named Timmy. Timmy loved to play with his toys, but he always wanted to share them with others. One day, Timmy was playing with his toy cars and accidentally broke them. His mom said, \"Don't worry, I will help you fix your toys. Let's make it together.\"\n",
      "So, Timmy went to his room and started to play with his toy cars. He had so much fun playing with it, he didn't even want to lose it. His mom was happy to help, so they took a break and put the toy cars away in the right place. Timmy was very happy that he could share his toys with his mom.\n",
      "\n",
      "\n",
      "Step 4000, Loss: 1.4644711017608643, Elapsed Time: 69.17 seconds\n",
      "Generated text:\n",
      "Once upon a time, there was a little girl named Lily. She loved to play in the garden, and even when she saw a beautiful butterfly. She ran over to the butterfly and tried to catch it, but it flew away. \n",
      "Suddenly, a little girl appeared. She looked around and saw her and asked her what she was doing. Lily replied, \"I want to play too, please!\" Her mom replied, \"Okay, but only if you don't like the butterfly, it's better.\" \n",
      "So, Lily decided to go back to the garden to find the butterfly. She walked over to the garden and saw a big, beautiful butterfly. The butterfly flapped its wings and flew away. Lily felt so happy that she ran back to the garden, happy that she could play with the butterfly again.\n",
      "\n",
      "\n",
      "Step 4200, Loss: 1.4640543460845947, Elapsed Time: 72.24 seconds\n",
      "Generated text:\n",
      "Once upon a time, there was a boy named Timmy. Timmy loved to play with his toy cars, trucks and even the cars. One day, Timmy's toy car got stuck in a big mud. Timmy tried to get the wheels, but he was too heavy. He tried to push the wheel but it was too heavy. Timmy tried and tried, but he couldn't do it. Timmy was sad, but then he remembered how his mom told him. He was brave and strong, but he knew how to use his car to get it. He was happy again, and he was able to get the wheel.\n",
      "\n",
      "\n",
      "Step 4400, Loss: 1.4368994235992432, Elapsed Time: 66.23 seconds\n",
      "Generated text:\n",
      "Once upon a time, there was a little boy named Timmy. Timmy loved to play outside and pick flowers. One day, he saw a little boy who was very curious. He went up to him and asked, \"Can I help you?\" The boy replied, \"Sure, you can help me find your way.\"\n",
      "Timmy and the boy searched everywhere but they couldn't find the way up to the boy. They searched everywhere but they couldn't find the answer. Suddenly, the boy said, \"Don't worry, I'll help you find your way.\" Timmy said, \"I know how to solve this problem.\"\n",
      "Timmy's face lit up with excitement and said, \"I'll help you solve this problem. I can find your way home.\" His mom said, \"That's right. Let's find your way and see if we can find a way to find my way back.\" Timmy and the boy looked at each other's hand and said, \"Yes, I'll help you.\"\n",
      "They found a small tree, and Timmy helped his mom get his help. They worked together to search for the little boy's journey. After a few hours, they finally found the perfect path. Timmy was so happy that he could!!!!\n",
      "\n",
      "Step 4600, Loss: 1.4162362813949585, Elapsed Time: 88.24 seconds\n",
      "Generated text:\n",
      "Once upon a time, there was a little boy named Timmy. Timmy loved to play outside and look at the pretty flowers. One day, Timmy saw a beautiful flower. It was so pretty and he wanted to touch it. \n",
      "But when he got close to the flower, he accidentally dropped it. It broke! Timmy was so sad that he cried and his mom couldn't fix it. She said they would get another special thing, but Timmy was okay. \n",
      "His mom hugged him and said it was okay. She told him that accidents happen and that it's important to be careful when you touch things that can happen.\n",
      "\n",
      "\n",
      "Step 4800, Loss: 1.4360578060150146, Elapsed Time: 66.49 seconds\n",
      "Generated text:\n",
      "Once upon a time, there was a little girl named Lily. She loved to play outside in the park. One day, she saw a big tree and wanted to climb it. But her mom told her to be careful because the tree might hurt them.\n",
      "Lily tried to climb the tree, but she was too weak. She fell down and started to cry. Her mom hugged her and told her to go back home. They were very happy and went back to the tree.\n",
      "\n",
      "\n",
      "Step 5000, Loss: 1.4377806186676025, Elapsed Time: 59.31 seconds\n",
      "Generated text:\n",
      "Once upon a time, there was a little girl named Lily. She loved to play outside and collect things. One day, she went to the park with her mom. She saw a boy sitting at the bench and he said, \"Hello, doggy!\" Lily felt embarrassed because she didn't like it. She asked the boy, \"What's wrong?\" The boy said, \"My dog's dog bit me!\" Lily said, \"It's too bad. I'm too small.\" The boy felt sad for her.\n",
      "Lily said, \"I'm sorry, but I don't know it's not good.\" She went to her mom and asked if she could borrow some of her toys. Her mom said, \"Sure, you can borrow your toy car. You can borrow it, but be careful.\" Lily smiled and went back to playing with her toy car. She had a lot of fun with her toy car and played with it all day.\n",
      "\n",
      "\n",
      "Step 5200, Loss: 1.3954946994781494, Elapsed Time: 76.86 seconds\n",
      "Generated text:\n",
      "Once upon a time, there was a little girl named Lily. She loved to play outside and pick flowers. One day, she saw a beautiful flower in the garden. She picked it up and held it in her hand. She felt so happy that she wanted to show her mom.\n",
      "Her mom came outside and saw that Lily was very sad. She told Lily that the flower was still a flower. Lily felt sorry for being so pretty. She promised to be more careful with the flower.\n",
      "The next day, Lily went back outside to pick some flowers. She found some pretty flowers and showed them to her mom. Her mom was very happy and said that Lily's flower was not as pretty as the flowers in the garden. From that day on, Lily loved to play and make pretty flowers in the garden.\n",
      "\n",
      "\n",
      "Step 5400, Loss: 1.401665449142456, Elapsed Time: 70.89 seconds\n",
      "Generated text:\n",
      "Once upon a time, there was a little boy named Timmy. Timmy loved to play outside and explore. One day, Timmy saw a big tree with a lot of branches. He thought it looked interesting and decided to climb the tree. \n",
      "Timmy's friend, a wise old owl, said, \"Timmy, don't be careless. I don't want to fall. You need to get hurt.\" \n",
      "Timmy didn't understand why the owl was so wise, so he explained to his friends, \"It's important to always stay safe.\" \n",
      "Timmy felt better and went back to his tree to admire the branches from branch. He knew that even if something is too small, it's always better to be safe and be careful when climbing tree.\n",
      "\n",
      "\n",
      "Step 5600, Loss: 1.3960157632827759, Elapsed Time: 71.91 seconds\n",
      "Generated text:\n",
      "Once upon a time, a little girl named Lily went on a trip with her mommy. They were having so much fun. When they got to the beach, they saw a crab and wanted to touch it.\n",
      "Lily said, \"Mommy, can I touch the crab?\"\n",
      "\"No, it's too dangerous. You should stay in the sand. The crab might be safe,\" her mommy replied.\n",
      "Lily was sad and started to cry. \"I'm sorry, mommy. I didn't want to be hurt.\"\n",
      "Her mommy said, \"It's okay, sweetie. I'm glad you listened to your mommy and not touched the crab. Now you can't touch the crab's safety.\"\n",
      "Lily smiled and hugged her mommy. From that day on, they became good friends and they played together every day.\n",
      "\n",
      "\n",
      "Step 5800, Loss: 1.3838456869125366, Elapsed Time: 73.78 seconds\n",
      "Generated text:\n",
      "Once upon a time, there was a little boy named Tim. Tim had a big toy car. The car could go very fast. Tim liked to race with his car.\n",
      "One day, Tim saw a big box. He wanted to open it. Tim went to his friend, Sue. Sue saw the box and said, \"I can open this box!\" Sue wanted to open the box. They opened the box. Inside, there was a big, soft teddy bear. The bear was happy.\n",
      "Tim and Sue played with the bear all day. They were not very good at all. They played with the toys and had lots of fun. They learned that being kind was better and to help others. And from that day on, Tim and Sue were the best of friends.\n",
      "\n",
      "\n",
      "Step 6000, Loss: 1.4077720642089844, Elapsed Time: 70.17 seconds\n",
      "Generated text:\n",
      "Once upon a time, a little girl named Sue and her dog, Spot. They lived in a big house with their mom and dad. One day, they found a shiny rock that they had to take home. They took it home and put it in their room.\n",
      "Sue's mom saw the shiny rock and said, \"Oh, my toy! Your toy is very special! You should take it home.\" Sue was happy to have her toy back and said, \"Thank you, Spot!\"\n",
      "But then, a big wind came and blew the rock back. Sue and Spot got scared and started to cry. Their mom came and saw what happened. She told them not to worry and they both went to the toy store to get the shiny rock.\n",
      "The moral of the story is that it's important to take care of our things, but we can also take care of them. If you take care of them, we might find them and help them find them.\n",
      "\n",
      "\n",
      "Step 6200, Loss: 1.3794877529144287, Elapsed Time: 77.59 seconds\n",
      "Generated text:\n",
      "Once upon a time, there was a little girl named Lily. She loved to play outside and pick flowers. One day, she went to the park with her mommy. She saw a boy crying because he lost his toy car.\n",
      "Lily said, \"I lost my toy car, but I can't find it.\"\n",
      "Lily asked the boy, \"Have you seen my toy car?\" The boy said, \"No, I haven't seen it.\"\n",
      "Lily felt sad and went to play on the swings. She went to the boy and said, \"Thank you, you're my friend.\" The boy said, \"You are very kind. Can you help me find your toy car?\"\n",
      "Lily smiled and said, \"I will help you find your toy car. Maybe you can find your toy car.\"\n",
      "\n",
      "\n",
      "Step 6400, Loss: 1.3905563354492188, Elapsed Time: 73.45 seconds\n",
      "Generated text:\n",
      "Once upon a time, there was a little girl named Lily. She loved to play outside in the sun. One day, she saw a big, round thing on the ground. It was a pretty, shiny rock.\n",
      "Lily picked up the rock and put it on her foot. She was so happy and showed her mom the rock. Her mom was proud of her and gave her a big hug. Lily felt happy too.\n",
      "Later that day, Lily and her mom went to the park. Lily saw a big slide. She wanted to slide down it too. She ran up the slide, and slid down fast. The wind blew and Lily fell. She was hurt and sad.\n",
      "Lily learned to be careful when she slide. She went to the swings, and when she was playing, she felt much better. Her mom gave her a hug and told her to keep the smooth rock. Lily learned that she should always keep the rock safe.\n",
      "\n",
      "\n",
      "Step 6600, Loss: 1.39736008644104, Elapsed Time: 76.19 seconds\n",
      "Generated text:\n",
      "Once upon a time, there was a little girl named Lily. She loved to play with her toys and her favorite toy was a teddy bear. One day, Lily was playing with her teddy bear when she saw a shiny object on the ground. She picked it up and looked at it closely. \n",
      "\"Wow, look at that object!\" said Lily.\n",
      "\"I want it!\" said her mom. \"It's a special object. It's shiny and it's very special to me.\"\n",
      "Lily thought for a moment and then decided to take the object from her mom to her friend. \"Look, I found a pretty bracelet!\" said Lily. \n",
      "Her friend said, \"That's great, Lily! Let's play with it.\" And so, they played with the bracelet all day long. They were having so much fun!\n",
      "\n",
      "\n",
      "Step 6800, Loss: 1.4118915796279907, Elapsed Time: 72.23 seconds\n",
      "Generated text:\n",
      "Once upon a time, there was a little girl named Lily. She loved to draw with her toys and make pictures. One day, she was playing in her backyard when she saw a big bird sitting on a branch. The bird was so pretty! Lily wanted to be friends with the bird, so she tried to sing with it. But the bird didn't fly away. Lily was sad and didn't know what to do.\n",
      "Then, Lily saw a bird that it was very graceful. She asked the bird what was wrong. The bird said that it had wings to fly away. Lily thought that it was a fun idea and flew away. She was happy again and went back to her house to play. From that day on, Lily knew that if she wanted to be friends with her friend, she could help the bird feel better.\n",
      "\n",
      "\n",
      "Step 7000, Loss: 1.4061782360076904, Elapsed Time: 72.51 seconds\n",
      "Generated text:\n",
      "Once upon a time, a little girl named Sue lived in a big house. Sue had a toy car that she loved to play with. One day, Sue's mom told her not to clean up. Sue listened to her mom and started to clean her room.\n",
      "After cleaning, Sue felt tired and needed to take a nap. She put on her clean, but her mom was not looking well. Sue went to her room and sat down to rest. Her mom said, \"Sue, I'm going to rest and drink a big drink.\" Sue smiled and felt better.\n",
      "Sue went to bed with her mom to rest her room. In the end, she went to sleep with her mom. She felt happy that she was able to help her mom. From that day on, Sue knew that her mom loved her because she loved her little sister so much.\n",
      "\n",
      "\n",
      "Step 7200, Loss: 1.381988286972046, Elapsed Time: 73.38 seconds\n",
      "Generated text:\n",
      "Once upon a time, a little girl named Lily went to the park with her mommy. She saw a boy who looked sad. She went to her mommy and asked her if she could have a turn to her.\n",
      "\"Sure, but you have to ask your mommy,\" her mommy said. \"It's okay, but it's important to ask nicely.\"\n",
      "Lily nodded and gave the boy a hug. \"Can we play on the swings?\" she asked.\n",
      "The boy didn't like it and said, \"Sure, but be careful.\"\n",
      "Lily felt happy and went to play on the swings. She went back to the boy and asked if he wanted to swing too. The boy said, \"I want to swing like you, but it's not safe.\"\n",
      "Lily went to the swing and pushed the boy away. She was sad that she lost her favorite toy. The boy was upset and didn't want to swing anymore. They both sat on the swing and watched the boy play on the swings. Lily felt better and said, \"Thank you for letting me swing, Timmy. You're my friend.\"\n",
      "\n",
      "\n",
      "Step 7400, Loss: 1.3883332014083862, Elapsed Time: 83.07 seconds\n",
      "Generated text:\n",
      "Once upon a time, there was a little girl named Lily. She loved to play outside in the garden and feel the warm sunshine on her skin. One day, while she was playing, she noticed that the flowers had bloomed in a beautiful butterfly. She wanted to see the butterfly so she asked her mommy if she could go to the butterfly's home. Her mommy said yes and Lily ran to her mommy's room. \n",
      "When she got there, she saw that the butterfly was sad and started to cry. Her mommy told her that she couldn't go back to the garden to get her dress and her mommy was not happy. Lily felt bad and didn't want to go back to the garden to get her dress. \n",
      "The next day, Lily saw the butterfly again and ran back to her mommy's house. She was happy to see her mommy again and said she was a great helper. Her mommy was so happy that she could see the butterfly again and that was a beautiful butterfly who was a good girl.\n",
      "\n",
      "\n",
      "Step 7600, Loss: 1.3650509119033813, Elapsed Time: 80.14 seconds\n",
      "Generated text:\n",
      "Once upon a time, there was a little girl named Lily. She loved to play with her toys, but one day she got bored. She went to her friend, Tim, and asked if he could borrow his toy.\n",
      "Tim said, \"No, Lily. This is my toy car. You can play with it, but I want to borrow your toy car.\"\n",
      "Lily felt sad because she didn't want to play with Tim. She said, \"Please, Tim. We can borrow your toy car. I can borrow it for my birthday.\"\n",
      "Tim took the toy car and said, \"No, Lily. I can borrow it for my birthday.\" He played with the toy car all day. He was happy with his new toy car.\n",
      "\n",
      "\n",
      "Step 7800, Loss: 1.3602105379104614, Elapsed Time: 69.70 seconds\n",
      "Generated text:\n",
      "Once upon a time, a little girl named Lily went to a park with her mommy. The park was a pretty green place, with a big pond with lots of ducks. Lily loved the sound of the water, so she decided to play in the water.\n",
      "Lily saw a butterfly flying in the sky and tried to catch it. But the butterfly was too fast, and she couldn't catch it. Suddenly, the butterfly landed on a flower and Lily started to panic.\n",
      "Her mommy saw the butterfly and asked, \"What happened, Lily?\"\n",
      "\"The butterfly fell and hurt my hand,\" said Lily.\n",
      "Her mommy came over and saw the butterfly and asked, \"Are you okay, Lily?\"\n",
      "\"It hurts, sweetie,\" said her mommy.\n",
      "Lily's mommy took a big spoon and the butterfly was very pretty and had lots of colors on it. Lily felt much better and was able to catch the butterfly. She was happy to have her friend a little friend, and they played together all day long.\n",
      "\n",
      "\n",
      "Step 8000, Loss: 1.3417373895645142, Elapsed Time: 79.57 seconds\n",
      "Generated text:\n",
      "Once upon a time, there was a little boy named Tim. Tim had a toy named Sam. Sam liked to play with the toy car. One day, Tim's mom said they were going to a new park. Tim wanted to play on the swings, but his mom said no.\n",
      "Tim started playing with the car. He saw a big dog in the park. The dog barked loudly. Tim felt scared. He wanted to run away. He went to his mom and dad and said they were safe. Tim felt safe.\n",
      "Later, Tim and Sam went to the park. They saw a big slide. They both wanted to go on the slide. They ran to the slide and slid down the slide. Tim's mom and dad helped them get down. They all laughed and had a great time together.\n",
      "\n",
      "\n",
      "Step 8200, Loss: 1.3874244689941406, Elapsed Time: 71.68 seconds\n",
      "Generated text:\n",
      "Once upon a time, there was a little boy named Timmy. Timmy loved to play with his toy car, but his favorite thing to do was to go to the store. Timmy didn't like the store, so he went to the store.\n",
      "When they got to the store, Timmy saw a toy car and wanted it. He asked his mom for a toy car and her mom said, \"No, it's too expensive.\" Timmy didn't want to buy a toy car. He thought the toy car wouldn't have a toy car, but his mom said it was okay.\n",
      "Later that day, Timmy went to the park with his mom. Timmy saw a boy who looked sad because he lost his toy car. Timmy felt sorry for the boy and said, \"I can help you find my toy car.\" But he couldn't find his toy car, and he didn't know what to do.\n",
      "Timmy asked his mom, \"Why are you looking for my toy car, and the boy can have it back?\" His mom said, \"Don't worry, we can fix it. Let's find your toy car.\" They found the toy car and it was in the store. Timmy was happy that he found a!!!!\n",
      "\n",
      "Final generated text:\n",
      "Once upon a time, there was a little girl named Lily. She loved to play outside and pick flowers. One day, Lily saw a butterfly and tried to catch it, but it flew away. Lily felt sad because she didn't know what was happening.\n",
      "Suddenly, her friend, a little bird named Timmy, came to visit. \"Don't worry, Timmy,\" said Lily. \"I can catch it!\"\n",
      "\"I'm sorry, Lily,\" said Timmy. \"I just need to help my mom.\"\n",
      "\"Thank you, Timmy,\" said Lily. \"You are very kind to me.\"\n",
      "From that day on, Lily learned to always help others when they needed it. And every time she saw the butterfly, she felt happy again.\n",
      "\n"
     ]
    }
   ],
   "source": [
    "model = create_model(rngs=nnx.Rngs(0))\n",
    "optimizer = nnx.Optimizer(model, optax.adam(1e-3))\n",
    "metrics = nnx.MultiMetric(\n",
    "  loss=nnx.metrics.Average('loss'),\n",
    ")\n",
    "rng = jax.random.PRNGKey(0)\n",
    "\n",
    "start_prompt = \"Once upon a time\"\n",
    "start_tokens = tokenizer.encode(start_prompt)[:maxlen]\n",
    "generated_text = model.generate_text(\n",
    "    maxlen, start_tokens\n",
    ")\n",
    "print(f\"Initial generated text:\\n{generated_text}\\n\")\n",
    "\n",
    "\n",
    "metrics_history = {\n",
    "  'train_loss': [],\n",
    "}\n",
    "\n",
    "prep_target_batch = jax.vmap(lambda tokens: jnp.concatenate((tokens[1:], jnp.array([0]))))\n",
    "\n",
    "step = 0\n",
    "for epoch in range(num_epochs):\n",
    "    start_time = time.time()\n",
    "    for batch in text_dl:\n",
    "        if len(batch) % len(jax.devices()) != 0:\n",
    "          continue  # skip the remaining elements\n",
    "        input_batch = jnp.array(jnp.array(batch).T)\n",
    "        target_batch = prep_target_batch(input_batch)\n",
    "        train_step(model, optimizer, metrics, jax.device_put((input_batch, target_batch), NamedSharding(mesh, P('batch', None))))\n",
    "\n",
    "        if (step + 1) % 200 == 0:\n",
    "          for metric, value in metrics.compute().items():\n",
    "              metrics_history[f'train_{metric}'].append(value)\n",
    "          metrics.reset()\n",
    "\n",
    "          elapsed_time = time.time() - start_time\n",
    "          print(f\"Step {step + 1}, Loss: {metrics_history['train_loss'][-1]}, Elapsed Time: {elapsed_time:.2f} seconds\")\n",
    "          start_time = time.time()\n",
    "\n",
    "          generated_text = model.generate_text(\n",
    "              maxlen, start_tokens\n",
    "          )\n",
    "          print(f\"Generated text:\\n{generated_text}\\n\")\n",
    "        step += 1\n",
    "\n",
    "# Final text generation\n",
    "generated_text = model.generate_text(\n",
    "    maxlen, start_tokens\n",
    ")\n",
    "print(f\"Final generated text:\\n{generated_text}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "thaLs6TD0lt5"
   },
   "source": [
    "Visualize the training loss."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 472
    },
    "id": "B6Eg1Cz2y_iP",
    "outputId": "7cafe711-1ae4-4eb9-fd37-e1bde54cbfc5"
   },
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "plt.plot(metrics_history['train_loss'])\n",
    "plt.title('Training Loss')\n",
    "plt.xlabel('Step')\n",
    "plt.ylabel('Loss')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "WB-ExEt1Zl1C"
   },
   "source": [
    "As you can see, the model goes from generating completely random words at the beginning to generating sensible tiny stories at the end of the training. So essentially we have pretrained a small LLM to write tiny stories for us."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "soPqiR1JNmjf"
   },
   "source": [
    "## Saving\n",
    "Save the model checkpoint."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "EkoFGCgSZ1yz",
    "outputId": "3467b8ba-ce05-42f0-fb89-75922cc91e31"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "_CHECKPOINT_METADATA  d  manifest.ocdbt  _METADATA  ocdbt.process_0  _sharding\n"
     ]
    }
   ],
   "source": [
    "import orbax.checkpoint as orbax\n",
    "\n",
    "state = nnx.state(model)\n",
    "\n",
    "checkpointer = orbax.PyTreeCheckpointer()\n",
    "checkpointer.save('/content/save', state)\n",
    "\n",
    "# Make sure the files are there\n",
    "!ls /content/save/"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3813cbf2",
   "metadata": {},
   "source": [
    "## Profiling for Hyperparameter Tuning"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b5d933c6",
   "metadata": {},
   "outputs": [],
   "source": [
    "!pip install -Uq tensorboard-plugin-profile tensorflow tensorboard"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2ac5fc4d",
   "metadata": {},
   "source": [
    "Load the tensorboard colab extension."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "74f0c212",
   "metadata": {},
   "outputs": [],
   "source": [
    "%load_ext tensorboard"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "17c6131f",
   "metadata": {},
   "source": [
    "As we're going to be running this model a number of times, we need some scaffolding to more easily compare our work. For a baseline, we'll need to perform some warmup to guarantee that our code is JIT'd and that our TPUs are warm. For improved comparability, we'll only start tracing after we've finished warmup."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ddfd576e",
   "metadata": {},
   "outputs": [],
   "source": [
    "trace_dir = \"/tmp/jax-trace/\"\n",
    "\n",
    "def loop_step(batch, step):\n",
    "    input_batch = jnp.array(jnp.array(batch).T)\n",
    "    target_batch = prep_target_batch(input_batch)\n",
    "    train_step(model, optimizer, metrics, jax.device_put((input_batch, target_batch), NamedSharding(mesh, P('batch', None))))\n",
    "\n",
    "def generate_trace():\n",
    "    tracing_steps = 30\n",
    "    warmup_steps = 5\n",
    "    for current_step in range(warmup_steps + tracing_steps):\n",
    "        if current_step == warmup_steps:\n",
    "            jax.profiler.start_trace(trace_dir)\n",
    "        with jax.profiler.StepTraceAnnotation(\"train\", step_num=current_step):\n",
    "            batch = next(text_dl)\n",
    "            loop_step(batch, current_step)\n",
    "\n",
    "    jax.profiler.stop_trace()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "de70f5b7",
   "metadata": {},
   "source": [
    "Now we'll perform some traces to compare results of different batch sizes. This will take several minutes as we need to reprocess our input data to prepare new batches each time."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bc9452a6",
   "metadata": {},
   "outputs": [],
   "source": [
    "trace_dir = \"/tmp/jax-trace-batch-comparison/\"\n",
    "\n",
    "batch_size = 64\n",
    "text_dl = iter(load_and_preprocess_data('TinyStories-train.txt', batch_size, maxlen))\n",
    "generate_trace()\n",
    "\n",
    "batch_size = 256\n",
    "text_dl = iter(load_and_preprocess_data('TinyStories-train.txt', batch_size, maxlen))\n",
    "generate_trace()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ea379965",
   "metadata": {},
   "source": [
    "Run Tensorboard with the Profiler Plugin to compare our runs. Runs are listed in order from newest to oldest, so the top run in the list will be have `batch_size = 256`.\n",
    "\n",
    "The key metrics to focus on here for this hyperparameter are FLOPS Utilization and Average Step Time.\n",
    "\n",
    "In general, we want to maximize FLOPS Utilization while minimizing the step time per training example. In this case, we can see that increasing the batch size from 64 -> 256 achieves both of those. FLOPS increases from 16% to 27%. Average Step Time increase from 100ms to 260ms, however we increased our batch size by 300%. This means we move from 1.5ms per training example to 1.02ms per training example."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b86c565a",
   "metadata": {},
   "outputs": [],
   "source": [
    "%tensorboard --logdir=$trace_dir"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "657967a5",
   "metadata": {},
   "source": [
    "Next, we can explore alternative parallelism methods. In cell #4, we used 4-way data parallel and 2-way tensor parallel. 8-way data parallel is another popular way. Let's compare results between them. To switch to 8-way data parallel, we'll replace the `Mesh` definition with:\n",
    "\n",
    "`mesh = Mesh(mesh_utils.create_device_mesh((8, 1)), ('batch', 'model'))`\n",
    "\n",
    "JAX will automatically figure out how to shard the model and data to use the new partition strategy and nothing else need to be done. Re-connect the TPU runtime and run it again to see how it runs.\n",
    "\n",
    "How simple and powerful is this! And that's the beauty of JAX automatic parallelism."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "80daa8dc",
   "metadata": {},
   "outputs": [],
   "source": [
    "trace_dir = \"/tmp/jax-trace-parallelism-comparison/\"\n",
    "\n",
    "mesh = Mesh(mesh_utils.create_device_mesh((4, 2)), ('batch', 'model'))\n",
    "generate_trace()\n",
    "\n",
    "mesh = Mesh(mesh_utils.create_device_mesh((8, 1)), ('batch', 'model'))\n",
    "generate_trace()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ad96e72b",
   "metadata": {},
   "source": [
    "Once again we'll run tensorboard.\n",
    "\n",
    "Looking at the results, we see that the step times are nearly the same, however the FLOPS Utilization is at 13% for 8-way data parallelism compared to 27% or 4-way data parallelism.\n",
    "\n",
    "By looking at the Trace Viewer tool and looking under each TPU's ops, we can see that the TPUs spend a large amount of time idle while waiting for the host, as well as spending a good amount of time in `reduce_sum` operations."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "780e9c72",
   "metadata": {},
   "outputs": [],
   "source": [
    "%tensorboard --logdir=$trace_dir"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "deca486e",
   "metadata": {},
   "source": [
    "By changing hyperparameters and comparing profiles, we're able to gain significant insights into our bottlenecks and limitations. These are just two examples of hyperparameters to tune, but plenty more of them will have significant effects on training speed and resource utilization."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "jCApVd7671c1"
   },
   "source": [
    "## Disconnect the Colab runtime"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "id": "NsqYdbrDVKSq"
   },
   "outputs": [],
   "source": [
    "from google.colab import runtime\n",
    "runtime.unassign()"
   ]
  }
 ],
 "metadata": {
  "accelerator": "TPU",
  "colab": {
   "gpuType": "V28",
   "machine_shape": "hm",
   "provenance": []
  },
  "jupytext": {
   "formats": "ipynb,md:myst"
  },
  "kernelspec": {
   "display_name": "Python 3",
   "name": "python3"
  },
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
