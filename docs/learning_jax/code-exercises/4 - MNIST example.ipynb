{"cells":[{"cell_type":"markdown","id":"0","metadata":{"id":"0"},"source":["[![Open in Colab](https://colab.research.google.com/assets/colab-badge.svg)](https://colab.research.google.com/github/google/flax/blob/main/docs_nnx/mnist_tutorial.ipynb)\n","[![Open On GitHub](https://img.shields.io/badge/Open-on%20GitHub-blue?logo=GitHub)](https://github.com/google/flax/blob/main/docs_nnx/mnist_tutorial.ipynb)\n","\n","# MNIST tutorial\n","\n","Welcome to Flax NNX! In this tutorial you will learn how to build and train a simple convolutional neural network (CNN) to classify handwritten digits on the MNIST dataset using the Flax NNX API.\n","\n","Flax NNX is a Python neural network library built upon [JAX](https://github.com/jax-ml/jax). If you have used the Flax Linen API before, check out [Why Flax NNX](https://flax.readthedocs.io/en/latest/why.html). You should have some knowledge of the main concepts of deep learning.\n","\n","Let’s get started!"]},{"cell_type":"markdown","id":"1","metadata":{"id":"1"},"source":["## 1. Install Flax and Optax"]},{"cell_type":"code","execution_count":null,"id":"2","metadata":{"tags":["skip-execution"],"id":"2"},"outputs":[],"source":["!pip install -Uq flax optax"]},{"cell_type":"markdown","id":"3","metadata":{"id":"3"},"source":["## 2. Load the MNIST dataset\n","\n","First, you need to load the MNIST dataset and then prepare the training and testing sets via Tensorflow Datasets (TFDS). You normalize image values, shuffle the data and divide it into batches, and prefetch samples to enhance performance."]},{"cell_type":"code","execution_count":null,"id":"4","metadata":{"id":"4"},"outputs":[],"source":["import tensorflow_datasets as tfds  # TFDS to download MNIST.\n","import tensorflow as tf  # TensorFlow / `tf.data` operations.\n","\n","tf.random.set_seed(0)  # Set the random seed for reproducibility.\n","\n","train_steps = 1200\n","eval_every = 200\n","batch_size = 32\n","\n","train_ds: tf.data.Dataset = tfds.load('mnist', split='train')\n","test_ds: tf.data.Dataset = tfds.load('mnist', split='test')\n","\n","train_ds = train_ds.map(\n","  lambda sample: {\n","    'image': tf.cast(sample['image'], tf.float32) / 255,\n","    'label': sample['label'],\n","  }\n",")  # Normalize train set\n","\n","test_ds = test_ds.map(\n","  lambda sample: {\n","    'image': tf.cast(sample['image'], tf.float32) / 255,\n","    'label': sample['label'],\n","  }\n",")  # Normalize the test set\n","\n","# Create a shuffled dataset by allocating a buffer size of 1024 to randomly draw elements from.\n","train_ds = train_ds.repeat().shuffle(1024)\n","# Group into batches of `batch_size` and skip incomplete batches, prefetch the next sample to improve latency.\n","train_ds = train_ds.batch(batch_size, drop_remainder=True).take(train_steps).prefetch(1)\n","# Group into batches of `batch_size` and skip incomplete batches, prefetch the next sample to improve latency.\n","test_ds = test_ds.batch(batch_size, drop_remainder=True).prefetch(1)"]},{"cell_type":"markdown","id":"5","metadata":{"id":"5"},"source":["## 3. Define the model with Flax NNX\n","\n","Create a CNN for classification with Flax NNX by subclassing `nnx.Module`:"]},{"cell_type":"code","execution_count":null,"id":"6","metadata":{"id":"6"},"outputs":[],"source":["from flax import nnx  # The Flax NNX API.\n","from functools import partial\n","\n","class CNN(nnx.Module):\n","  \"\"\"A simple CNN model.\"\"\"\n","\n","  def __init__(self, *, rngs: nnx.Rngs):\n","    self.conv1 = nnx.Conv(1, 32, kernel_size=(3, 3), rngs=rngs)\n","    self.conv2 = nnx.Conv(32, 64, kernel_size=(3, 3), rngs=rngs)\n","    self.avg_pool = partial(nnx.avg_pool, window_shape=(2, 2), strides=(2, 2))\n","    self.linear1 = nnx.Linear(3136, 256, rngs=rngs)\n","    self.linear2 = nnx.Linear(256, 10, rngs=rngs)\n","\n","  def __call__(self, x):\n","    x = self.avg_pool(nnx.relu(self.conv1(x)))\n","    x = self.avg_pool(nnx.relu(self.conv2(x)))\n","    x = x.reshape(x.shape[0], -1)  # flatten\n","    x = nnx.relu(self.linear1(x))\n","    x = self.linear2(x)\n","    return x\n","\n","# Instantiate the model.\n","model = CNN(rngs=nnx.Rngs(0))\n","# Visualize it.\n","nnx.display(model)"]},{"cell_type":"markdown","id":"7","metadata":{"id":"7"},"source":["### Run the model\n","\n","Let's put the CNN model to the test!  Here, you’ll perform a forward pass with arbitrary data and print the results."]},{"cell_type":"code","execution_count":null,"id":"8","metadata":{"id":"8"},"outputs":[],"source":["import jax.numpy as jnp  # JAX NumPy\n","\n","y = model(jnp.ones((1, 28, 28, 1)))\n","y"]},{"cell_type":"markdown","id":"9","metadata":{"id":"9"},"source":["## 4. Create the optimizer and define some metrics\n","\n","In Flax NNX, you need to create an `nnx.Optimizer` object to manage the model's parameters and apply gradients during training. The `nnx.Optimizer` is initialized with the model to infer the structure of the optimizer state, and an Optax optimizer to define the update rules."]},{"cell_type":"code","execution_count":null,"id":"12","metadata":{"id":"12"},"outputs":[],"source":["import optax\n","\n","learning_rate = 0.005\n","momentum = 0.9\n","\n","optimizer = nnx.Optimizer(model, optax.adamw(learning_rate, momentum), wrt=nnx.Param)\n","metrics = nnx.MultiMetric(\n","  accuracy=nnx.metrics.Accuracy(),\n","  loss=nnx.metrics.Average('loss'),\n",")\n","\n","nnx.display(optimizer)"]},{"cell_type":"markdown","id":"13","metadata":{"id":"13"},"source":["## 5. Define training step functions\n","\n","In this section, you will define a loss function using the cross entropy loss ([`optax.softmax_cross_entropy_with_integer_labels()`](https://optax.readthedocs.io/en/latest/api/losses.html#optax.softmax_cross_entropy_with_integer_labels)) that the CNN model will optimize over.\n","\n","In addition to the `loss`, during training and testing you will also get the `logits`, which will be used to calculate the accuracy metric.\n","\n","During training - the `train_step` - you will use `nnx.value_and_grad` to compute the gradients and update the model's parameters using the `optimizer` you have already defined. And during both training and testing (the `eval_step`), the `loss` and `logits` will be used to calculate the metrics."]},{"cell_type":"code","execution_count":null,"id":"14","metadata":{"id":"14"},"outputs":[],"source":["def loss_fn(model: CNN, batch):\n","  logits = model(batch['image'])\n","  loss = optax.softmax_cross_entropy_with_integer_labels(\n","    logits=logits, labels=batch['label']\n","  ).mean()\n","  return loss, logits\n","\n","@nnx.jit\n","def train_step(model: CNN, optimizer: nnx.Optimizer, metrics: nnx.MultiMetric, batch):\n","  \"\"\"Train for a single step.\"\"\"\n","  grad_fn = nnx.value_and_grad(loss_fn, has_aux=True)\n","  (loss, logits), grads = grad_fn(model, batch)\n","  metrics.update(loss=loss, logits=logits, labels=batch['label'])  # In-place updates.\n","  optimizer.update(model, grads)  # In-place updates.\n","\n","@nnx.jit\n","def eval_step(model: CNN, metrics: nnx.MultiMetric, batch):\n","  loss, logits = loss_fn(model, batch)\n","  metrics.update(loss=loss, logits=logits, labels=batch['label'])  # In-place updates."]},{"cell_type":"markdown","id":"17","metadata":{"id":"17"},"source":["In the code above, the [`nnx.jit`](https://flax.readthedocs.io/en/latest/api_reference/flax.nnx/transforms.html#flax.nnx.jit) transformation decorator traces the `train_step` function for just-in-time compilation with [XLA](https://www.tensorflow.org/xla), optimizing performance on hardware accelerators, such as Google TPUs and GPUs. `nnx.jit` is a \"lifted\" version of the `jax.jit` transform that allows its function input and outputs to be Flax NNX objects. Similarly, `nnx.value_and_grad ` is a lifted version of `jax.value_and_grad `. Check out [the lifted transforms guide](https://flax.readthedocs.io/en/latest/guides/transforms.html) to learn more.\n","\n","> **Note:** The code shows how to perform several in-place updates to the model, the optimizer, and the metrics, but _state updates_ were not explicitly returned. This is because Flax NNX transformations respect _reference semantics_ for Flax NNX objects, and will propagate the state updates of the objects passed as input arguments. This is a key feature of Flax NNX that allows for a more concise and readable code. You can learn more in [Why Flax NNX](https://flax.readthedocs.io/en/latest/why.html)."]},{"cell_type":"markdown","id":"21","metadata":{"id":"21"},"source":["## 6. Train and evaluate the model\n","\n","Now, you can train the CNN model using batches of data for 10 epochs, evaluate the model’s performance\n","on the test set after each epoch, and log the training and testing metrics (the loss and\n","the accuracy) during the process. Typically this leads to the model achieving around 99% accuracy."]},{"cell_type":"code","execution_count":null,"id":"22","metadata":{"id":"22"},"outputs":[],"source":["from IPython.display import clear_output\n","import matplotlib.pyplot as plt\n","\n","metrics_history = {\n","  'train_loss': [],\n","  'train_accuracy': [],\n","  'test_loss': [],\n","  'test_accuracy': [],\n","}\n","\n","for step, batch in enumerate(train_ds.as_numpy_iterator()):\n","  # Run the optimization for one step and make a stateful update to the following:\n","  # - The train state's model parameters\n","  # - The optimizer state\n","  # - The training loss and accuracy batch metrics\n","  train_step(model, optimizer, metrics, batch)\n","\n","  if step > 0 and (step % eval_every == 0 or step == train_steps - 1):  # One training epoch has passed.\n","    # Log the training metrics.\n","    for metric, value in metrics.compute().items():  # Compute the metrics.\n","      metrics_history[f'train_{metric}'].append(value)  # Record the metrics.\n","    metrics.reset()  # Reset the metrics for the test set.\n","\n","    # Compute the metrics on the test set after each training epoch.\n","    for test_batch in test_ds.as_numpy_iterator():\n","      eval_step(model, metrics, test_batch)\n","\n","    # Log the test metrics.\n","    for metric, value in metrics.compute().items():\n","      metrics_history[f'test_{metric}'].append(value)\n","    metrics.reset()  # Reset the metrics for the next training epoch.\n","\n","    clear_output(wait=True)\n","    # Plot loss and accuracy in subplots\n","    fig, (ax1, ax2) = plt.subplots(1, 2, figsize=(15, 5))\n","    ax1.set_title('Loss')\n","    ax2.set_title('Accuracy')\n","    for dataset in ('train', 'test'):\n","      ax1.plot(metrics_history[f'{dataset}_loss'], label=f'{dataset}_loss')\n","      ax2.plot(metrics_history[f'{dataset}_accuracy'], label=f'{dataset}_accuracy')\n","    ax1.legend()\n","    ax2.legend()\n","    plt.show()"]},{"cell_type":"markdown","id":"25","metadata":{"id":"25"},"source":["## 7. Perform inference on the test set\n","\n","Create a `jit`-compiled model inference function (with `nnx.jit`) - `pred_step` - to generate predictions on the test set using the learned model parameters. This will enable you to visualize test images alongside their predicted labels for a qualitative assessment of model performance."]},{"cell_type":"code","execution_count":null,"id":"26","metadata":{"id":"26"},"outputs":[],"source":["model.eval() # Switch to evaluation mode.\n","\n","@nnx.jit\n","def pred_step(model: CNN, batch):\n","  logits = model(batch['image'])\n","  return logits.argmax(axis=1)"]},{"cell_type":"markdown","id":"1d6cb81f","metadata":{"id":"1d6cb81f"},"source":["Note that we use `.eval()` to ensure that the model is in evaluation mode, even though we are not using `Dropout` or `BatchNorm` in this model, `.eval()` ensure that the outputs are deterministic."]},{"cell_type":"code","execution_count":null,"id":"27","metadata":{"id":"27"},"outputs":[],"source":["test_batch = test_ds.as_numpy_iterator().next()\n","pred = pred_step(model, test_batch)\n","\n","fig, axs = plt.subplots(5, 5, figsize=(12, 12))\n","for i, ax in enumerate(axs.flatten()):\n","  ax.imshow(test_batch['image'][i, ..., 0], cmap='gray')\n","  ax.set_title(f'label={pred[i]}')\n","  ax.axis('off')"]},{"cell_type":"markdown","source":["## Exploring your model with Model Explorer\n","\n","To really dig into a model and understand the operations and connections, [Model Explorer](https://github.com/google-ai-edge/model-explorer/wiki/) is a great tool!  Let's take a look now at our MNIST model.  **Please feel free to poke around and explore the model!**"],"metadata":{"id":"N7n2PfE4LwMC"},"id":"N7n2PfE4LwMC"},{"cell_type":"code","source":["# Install Model Explorer\n","\n","!pip install --no-deps ai-edge-model-explorer-adapter ai-edge-model-explorer"],"metadata":{"id":"RLhM4CYkOaIh"},"id":"RLhM4CYkOaIh","execution_count":null,"outputs":[]},{"cell_type":"code","source":["# Use some dummy input and write the model MLIR to a file\n","\n","import jax\n","dummy_input = jnp.ones((1, 28, 28, 1))\n","stablehlo_mlir = jax.jit(model).lower(dummy_input).as_text(debug_info=True)\n","mlir_file = open(\"stablehlo_mlir.mlir\", \"w\")\n","mlir_file.write(stablehlo_mlir)\n","mlir_file.close()"],"metadata":{"id":"wo0F_ytxMAEq"},"id":"wo0F_ytxMAEq","execution_count":null,"outputs":[]},{"cell_type":"code","source":["# Import and run Model Explorer with the model\n","\n","import model_explorer\n","\n","model_explorer.visualize(\"stablehlo_mlir.mlir\")"],"metadata":{"id":"bbtTtGTmOmGX"},"id":"bbtTtGTmOmGX","execution_count":null,"outputs":[]},{"cell_type":"markdown","id":"28","metadata":{"id":"28"},"source":["Congratulations! You have learned how to use Flax NNX to build and train a simple classification model end-to-end on the MNIST dataset.\n","\n","Next, check out [Why Flax NNX?](https://flax.readthedocs.io/en/latest/why.html) and get started with a series of [Flax NNX Guides](https://flax.readthedocs.io/en/latest/guides/index.html)."]}],"metadata":{"jupytext":{"formats":"ipynb,md:myst","main_language":"python"},"language_info":{"name":"python"},"colab":{"provenance":[{"file_id":"14rZHWSa2Kw_vv-EMYr0eGqa21E4iald9","timestamp":1755113849998},{"file_id":"https://github.com/google/flax/blob/main/docs_nnx/mnist_tutorial.ipynb","timestamp":1748370481980}]},"kernelspec":{"name":"python3","display_name":"Python 3"}},"nbformat":4,"nbformat_minor":5}